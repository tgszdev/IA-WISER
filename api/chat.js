// Chat API com integra√ß√£o ao Supabase e modelo Gemini atualizado
import { GoogleGenerativeAI } from '@google/generative-ai';
import { queryDatabase } from './database.js';

// Armazenamento em mem√≥ria para sess√µes e configura√ß√µes
const sessionStore = global.sessionStore || new Map();
global.sessionStore = sessionStore;

const configStore = global.configStore || new Map();
global.configStore = configStore;

// Fun√ß√£o auxiliar para gerar ID √∫nico
function generateId() {
  return Date.now().toString(36) + Math.random().toString(36).substr(2);
}

// Fun√ß√£o para obter configura√ß√£o (mem√≥ria ou env)
function getConfig(key) {
  // Prioridade: 1. Mem√≥ria, 2. Vari√°veis de Ambiente
  const envMap = {
    'google_api_key': process.env.GOOGLE_API_KEY,
    'db_url': process.env.DATABASE_URL,
    'system_prompt': process.env.SYSTEM_PROMPT
  };
  
  return configStore.get(key) || envMap[key] || null;
}

// Fun√ß√£o para construir o prompt completo
function buildPrompt(systemPrompt, history, databaseContext, userMessage) {
  let prompt = "";
  
  // Se h√° contexto do banco, SOBRESCREVER TUDO e FOR√áAR uso
  if (databaseContext && databaseContext.results && databaseContext.results.length > 0) {
    prompt = "VOC√ä √â UM ASSISTENTE QUE RESPONDE BASEADO EXCLUSIVAMENTE NA BASE DE CONHECIMENTO ABAIXO.\n";
    prompt += "REGRA ABSOLUTA: USE APENAS AS INFORMA√á√ïES FORNECIDAS ABAIXO PARA RESPONDER.\n";
    prompt += "N√ÉO INVENTE INFORMA√á√ïES. SE N√ÉO ESTIVER NA BASE, DIGA QUE N√ÉO TEM A INFORMA√á√ÉO.\n";
    prompt += "SEMPRE CITE QUAL INFORMA√á√ÉO DA BASE VOC√ä EST√Å USANDO.\n\n";
    prompt += systemPrompt || "Responda sempre em portugu√™s do Brasil.";
  } else {
    prompt = systemPrompt || "Voc√™ √© um assistente de IA √∫til e prestativo. Responda sempre em portugu√™s do Brasil.";
  }
  
  // Adicionar hist√≥rico da conversa
  if (history && history.length > 0) {
    prompt += "\n\n### Hist√≥rico da Conversa:\n";
    history.forEach(msg => {
      prompt += `[${msg.role === 'user' ? 'Usu√°rio' : 'Assistente'}]: ${msg.content}\n`;
    });
  }
  
  // Adicionar contexto do banco de dados com √™nfase ABSOLUTA
  if (databaseContext && databaseContext.results && databaseContext.results.length > 0) {
    prompt += "\n\n‚ÄºÔ∏è‚ÄºÔ∏è‚ÄºÔ∏è BASE DE CONHECIMENTO DA EMPRESA - INFORMA√á√ïES OFICIAIS ‚ÄºÔ∏è‚ÄºÔ∏è‚ÄºÔ∏è\n";
    prompt += "================================================================\n";
    prompt += "üî¥ ATEN√á√ÉO: AS INFORMA√á√ïES ABAIXO S√ÉO AS √öNICAS QUE VOC√ä DEVE USAR!\n";
    prompt += "üî¥ N√ÉO USE CONHECIMENTO EXTERNO! USE APENAS O QUE EST√Å ESCRITO ABAIXO!\n\n";
    
    databaseContext.results.forEach((record, index) => {
      prompt += `\n‚≠ê INFORMA√á√ÉO ${index + 1}:\n`;
      prompt += `T√çTULO: ${record.title}\n`;
      prompt += `CONTE√öDO: ${record.content}\n`;
      if (record.category) {
        prompt += `CATEGORIA: ${record.category}\n`;
      }
      if (record.tags && record.tags.length > 0) {
        prompt += `TAGS: ${record.tags.join(', ')}\n`;
      }
      prompt += "\n";
    });
    
    prompt += "\nüî¥üî¥üî¥ INSTRU√á√ÉO FINAL OBRIGAT√ìRIA üî¥üî¥üî¥\n";
    prompt += "1. USE AS INFORMA√á√ïES ACIMA PARA RESPONDER\n";
    prompt += "2. CITE ESPECIFICAMENTE QUAL INFORMA√á√ÉO VOC√ä EST√Å USANDO\n";
    prompt += "3. N√ÉO INVENTE DADOS - USE APENAS O QUE FOI FORNECIDO\n";
    prompt += "4. SE A PERGUNTA N√ÉO PODE SER RESPONDIDA COM OS DADOS ACIMA, DIGA ISSO\n";
  }
  
  // Adicionar pergunta com instru√ß√£o final
  if (databaseContext && databaseContext.results && databaseContext.results.length > 0) {
    prompt += `\n\n### Pergunta do Usu√°rio:\n${userMessage}\n`;
    prompt += "\nüî¥ LEMBRETE FINAL: Use as informa√ß√µes da BASE DE CONHECIMENTO OFICIAL acima para responder!\n";
    prompt += "\n### Sua Resposta (baseada na base de conhecimento, em portugu√™s do Brasil):";
  } else {
    prompt += `\n\n### Pergunta do Usu√°rio:\n${userMessage}`;
    prompt += "\n\n### Sua Resposta (em portugu√™s do Brasil):";
  }
  
  return prompt;
}

export default async function handler(req, res) {
  // Configurar CORS
  res.setHeader('Access-Control-Allow-Credentials', true);
  res.setHeader('Access-Control-Allow-Origin', '*');
  res.setHeader('Access-Control-Allow-Methods', 'GET,OPTIONS,PATCH,DELETE,POST,PUT');
  res.setHeader(
    'Access-Control-Allow-Headers',
    'X-CSRF-Token, X-Requested-With, Accept, Accept-Version, Content-Length, Content-MD5, Content-Type, Date, X-Api-Version'
  );

  if (req.method === 'OPTIONS') {
    res.status(200).end();
    return;
  }

  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method not allowed' });
  }

  try {
    const { message, sessionId, history } = req.body;
    
    if (!message) {
      return res.status(400).json({
        error: 'Mensagem n√£o pode estar vazia'
      });
    }

    console.log('Processing message:', message);

    // Obter configura√ß√µes
    const apiKey = getConfig('google_api_key');
    const dbUrl = getConfig('db_url');
    const systemPrompt = getConfig('system_prompt');
    
    console.log('Config loaded - Has API Key:', !!apiKey, 'Has DB URL:', !!dbUrl);
    
    if (!apiKey) {
      return res.status(200).json({
        id: generateId(),
        role: 'assistant',
        content: `‚ö†Ô∏è API do Google n√£o configurada!

Para configurar:
1. Obtenha sua API key em: https://aistudio.google.com
2. No dashboard da Vercel, v√° em Settings ‚Üí Environment Variables
3. Adicione GOOGLE_API_KEY com sua chave
4. Fa√ßa redeploy do projeto

Ou configure temporariamente na p√°gina de Configura√ß√µes (√≠cone ‚öôÔ∏è).`,
        timestamp: new Date().toISOString(),
        error: true
      });
    }
    
    // Buscar contexto do banco de dados se configurado
    let databaseContext = null;
    let dbStatus = 'not_configured';
    
    if (dbUrl) {
      try {
        console.log('Querying database for:', message);
        // SEMPRE passar uma query, mesmo vazia, para buscar TODOS os dados
        databaseContext = await queryDatabase(dbUrl, message || '');
        
        if (databaseContext) {
          if (databaseContext.error) {
            console.log('Database warning:', databaseContext.error);
            dbStatus = 'error';
          } else if (databaseContext.results && databaseContext.results.length > 0) {
            console.log(`Database returned ${databaseContext.results.length} results`);
            console.log('FORCING AI to use database context!');
            dbStatus = 'found_data';
            
            // LOG DETALHADO para debug
            console.log('Database content being sent to AI:');
            databaseContext.results.forEach((r, i) => {
              console.log(`  ${i+1}. ${r.title}: ${r.content.substring(0, 100)}...`);
            });
          } else {
            console.log('Database returned no results - trying to fetch ALL');
            // Tentar buscar TODOS os registros se n√£o achou espec√≠ficos
            databaseContext = await queryDatabase(dbUrl, '');
            if (databaseContext && databaseContext.results && databaseContext.results.length > 0) {
              dbStatus = 'found_data';
              console.log(`Got ${databaseContext.results.length} records on second attempt`);
            } else {
              dbStatus = 'no_data';
            }
          }
        }
      } catch (dbError) {
        console.error('Database query error:', dbError);
        dbStatus = 'error';
      }
    }
    
    // Construir prompt
    const fullPrompt = buildPrompt(
      systemPrompt || '',
      history || [],
      databaseContext,
      message
    );
    
    console.log('Database status:', dbStatus);
    console.log('Prompt includes context:', !!(databaseContext && databaseContext.results && databaseContext.results.length > 0));
    
    // Chamar Google AI com modelo atualizado
    const genAI = new GoogleGenerativeAI(apiKey);
    
    // Usar gemini-1.5-flash que √© o modelo mais recente e dispon√≠vel
    let model;
    let text;
    
    try {
      // Tentar primeiro o gemini-1.5-flash (mais r√°pido e eficiente)
      model = genAI.getGenerativeModel({ model: "gemini-1.5-flash" });
      const result = await model.generateContent(fullPrompt);
      const response = await result.response;
      text = response.text();
    } catch (modelError) {
      console.log('Trying alternative model...');
      try {
        // Se falhar, tentar gemini-1.5-pro
        model = genAI.getGenerativeModel({ model: "gemini-1.5-pro" });
        const result = await model.generateContent(fullPrompt);
        const response = await result.response;
        text = response.text();
      } catch (modelError2) {
        // Se ainda falhar, tentar o modelo legado
        console.log('Trying legacy model...');
        model = genAI.getGenerativeModel({ model: "gemini-1.0-pro" });
        const result = await model.generateContent(fullPrompt);
        const response = await result.response;
        text = response.text();
      }
    }
    
    // Adicionar indicador se usou dados do banco
    if (dbStatus === 'found_data') {
      text += "\n\nüìä *[Resposta baseada na base de conhecimento]*";
    } else if (dbStatus === 'no_data' && dbUrl) {
      text += "\n\nüí° *[Nenhum dado relevante encontrado na base de conhecimento]*";
    }
    
    // Criar mensagem de resposta
    const responseMessage = {
      id: generateId(),
      role: 'assistant',
      content: text,
      timestamp: new Date().toISOString(),
      hasContext: dbStatus === 'found_data',
      dbStatus: dbStatus
    };
    
    // Salvar no hist√≥rico da sess√£o (em mem√≥ria)
    const sessionKey = `session_${sessionId}`;
    let chatHistory = sessionStore.get(sessionKey) || [];
    
    // Adicionar mensagem do usu√°rio e resposta ao hist√≥rico
    chatHistory.push({
      id: generateId(),
      role: 'user',
      content: message,
      timestamp: new Date().toISOString()
    });
    chatHistory.push(responseMessage);
    
    // Manter apenas as √∫ltimas 20 mensagens
    if (chatHistory.length > 20) {
      chatHistory = chatHistory.slice(-20);
    }
    
    // Salvar hist√≥rico atualizado
    sessionStore.set(sessionKey, chatHistory);
    
    return res.status(200).json(responseMessage);
    
  } catch (error) {
    console.error('Chat error:', error);
    console.error('Error stack:', error.stack);
    
    // Tratamento espec√≠fico de erros
    let errorMessage = 'Erro ao processar mensagem.';
    
    if (error.message) {
      if (error.message.includes('API_KEY_INVALID')) {
        errorMessage = 'API Key inv√°lida. Verifique se copiou corretamente do Google AI Studio.';
      } else if (error.message.includes('SAFETY')) {
        errorMessage = 'A mensagem foi bloqueada por quest√µes de seguran√ßa. Tente reformular.';
      } else if (error.message.includes('PERMISSION_DENIED')) {
        errorMessage = 'API Key sem permiss√£o. Verifique se a API est√° ativada no Google Cloud.';
      } else if (error.message.includes('quota')) {
        errorMessage = 'Cota da API excedida. Aguarde um momento ou verifique seu plano.';
      } else if (error.message.includes('404') && error.message.includes('model')) {
        errorMessage = 'Modelo de IA n√£o dispon√≠vel. O sistema est√° sendo atualizado. Tente novamente em instantes.';
      } else {
        errorMessage = `Erro: ${error.message}`;
      }
    }
    
    return res.status(200).json({
      id: generateId(),
      role: 'assistant',
      content: errorMessage,
      timestamp: new Date().toISOString(),
      error: true
    });
  }
}